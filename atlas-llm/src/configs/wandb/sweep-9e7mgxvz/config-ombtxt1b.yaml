wandb_version: 1

batch_size:
  value: 64
beta1:
  value: 0.9
beta2:
  value: 0.999
checkpoint_dir:
  value: checkpoints/model/gpt4-small-tinystories
checkpoint_interval:
  value: 1000
compile:
  value: true
context_length:
  value: 1024
cosine_iters:
  value: 100000
d_ff:
  value: 3072
d_model:
  value: 768
data_dtype:
  value: uint16
device:
  value: mps
eval_interval:
  value: 500
eval_iters:
  value: 100
gradient_clip_norm:
  value: 1
learning_rate:
  value: 0.0003
log_interval:
  value: 100
max_iters:
  value: 100000
min_lr:
  value: 6.0e-05
num_heads:
  value: 12
num_layers:
  value: 12
optimizer:
  value: adamw
resume_from:
  value: null
seed:
  value: 42
theta:
  value: 10000
train_data:
  value: data/tokenized/tinystories/train/TinyStoriesV2-GPT4-train_tokens_.bin
val_data:
  value: data/tokenized/tinystories/val/TinyStoriesV2-GPT4-valid_val_tokens_.bin
vocab_size:
  value: 50257
warmup_iters:
  value: 2000
weight_decay:
  value: 0.01
